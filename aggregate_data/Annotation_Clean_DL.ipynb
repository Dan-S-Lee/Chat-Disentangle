{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob as g\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def generate_uuid(row):\n",
    "    try:\n",
    "        uuid =  '_'.join(map(str, [row['date'].replace('-', '_'),\n",
    "                row['timestamp'].replace(':', '_'),\n",
    "                row['user'],\n",
    "                str(row['file_ind'])]))\n",
    "    except Exception as e:\n",
    "        print(row['file_ind'])\n",
    "        raise e\n",
    "    return uuid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def fill_missing_annots(df):\n",
    "    child_set = set(df['child'].tolist())\n",
    "    temp_df = df[~df['parent'].isin(child_set)].copy()\n",
    "    temp_df['child'] = temp_df['parent']\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    return temp_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class FileCleaner:\n",
    "    \"\"\"\n",
    "    Contains various methods to clean a raw .txt file.\n",
    "    \"\"\"\n",
    "    # Set patterns\n",
    "    TIMESTAMP_PATTERN = \"[[](\\d\\d:\\d\\d)[]]\"\n",
    "    USER_PATTERN = \"[[]\\d\\d:\\d\\d[]]\\s[<](.*?)[>]\"\n",
    "    MESSAGE_PATTERN = \".*[<].*[>](.*)\"\n",
    "    DATE_PATTERN = \"(\\d\\d\\d\\d-\\d\\d-\\d\\d)\"\n",
    "\n",
    "    NOON = 720\n",
    "\n",
    "    @staticmethod\n",
    "    def load_file(file_path):\n",
    "        \"\"\"\n",
    "\n",
    "        :param file_path: string of file path\n",
    "        :return: pandas DataFrame object with line text as one column\n",
    "        \"\"\"\n",
    "        return pd.read_csv(file_path, header = None, names = ['raw'], delimiter=\"\\t\")\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_uuid(row):\n",
    "        \"\"\"\n",
    "        Required column names in row: 'date', 'timestamp', 'user'\n",
    "        :param row: pandas dataframe row\n",
    "        :return: generated uuid from row parameters\n",
    "        \"\"\"\n",
    "        try:\n",
    "            uuid =  '_'.join(map(str, [row['date'].replace('-', '_'),\n",
    "                    row['timestamp'].replace(':', '_'),\n",
    "                    row['user'],\n",
    "                    str(row['file_ind'])]))\n",
    "        except Exception as e:\n",
    "            print(row['file_ind'])\n",
    "            raise e\n",
    "        return uuid\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_timestamp(raw_series):\n",
    "        \"\"\"\n",
    "\n",
    "        :param raw_series: \"raw\" column of data\n",
    "        :return: extracted timestamp Series\n",
    "        \"\"\"\n",
    "        time_series = raw_series.str.extract(FileCleaner.TIMESTAMP_PATTERN, expand=True)\n",
    "        #time_series = time_series.fillna(\"System\")\n",
    "        time_series = time_series.fillna(method='bfill')\n",
    "        return time_series\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_timestamp(raw_series):\n",
    "        \"\"\"\n",
    "        calculate raw minutes of dataset\n",
    "        :param raw_series: \"raw\" column of timestamp\n",
    "        :return: series of integers\n",
    "        \"\"\"\n",
    "\n",
    "        time_df = raw_series.str.split(':', expand=True)\n",
    "        time_df = time_df.fillna(method='bfill')\n",
    "        time_df = time_df.fillna(method='ffill')\n",
    "        #time_df = time_df.fillna(-1)\n",
    "        time_df['minutes_sum'] = time_df[0].astype(int) * 60 + time_df[1].astype(int)\n",
    "        return time_df['minutes_sum']\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_hour_minute(raw_series):\n",
    "        time_df = raw_series.str.split(':', expand=True)\n",
    "        time_df = time_df.fillna(method='bfill')\n",
    "        time_df = time_df.fillna(method='ffill')\n",
    "        time_df.columns = ['hour', 'minutes']\n",
    "        return time_df\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_12_to_24(raw_series):\n",
    "        new_series = raw_series.copy()\n",
    "        for ind, val in enumerate(raw_series.iloc[1:].values):\n",
    "            if raw_series.iloc[ind - 1] > raw_series.iloc[ind]:\n",
    "                new_series.update(raw_series.iloc[ind:] + FileCleaner.NOON)\n",
    "                break\n",
    "        return new_series\n",
    "\n",
    "    @staticmethod\n",
    "    def load_user_dict(user_dict_path, id_to_txt=False):\n",
    "        \"\"\"\n",
    "        Loads user_dict csv and returns dictionary key:user_txt, value:user_id\n",
    "        :param user_dict_path:\n",
    "        :return: dictionary\n",
    "        \"\"\"\n",
    "        map_df = pd.read_csv(user_dict_path, index_col=0)\n",
    "        if id_to_txt:\n",
    "            users_map = dict(zip(map_df['user_id'], map_df['user_txt']))\n",
    "        else:\n",
    "            users_map = dict(zip(map_df['user_txt'], map_df['user_id']))\n",
    "        return users_map\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_user(raw_series):\n",
    "        \"\"\"\n",
    "\n",
    "        :param raw_series: Series of raw message text\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        user_series = raw_series.str.extract(FileCleaner.USER_PATTERN, expand=True)\n",
    "        user_series = user_series.fillna(\"System\")\n",
    "        return user_series\n",
    "\n",
    "    @staticmethod\n",
    "    def map_user(user_series, user_map_path):\n",
    "        \"\"\"\n",
    "        Map string usernames to integer indices from users.csv\n",
    "        :param user_series:\n",
    "        :param user_map_path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        map_df = pd.read_csv(user_map_path, index_col=0)\n",
    "        users_map = dict(zip(map_df['user_txt'], map_df['user_id']))\n",
    "        return user_series.map(users_map)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_mentions(raw_series, users_map):\n",
    "        mentioned_users_series = raw_series.apply(lambda x: FileCleaner.retrieve_user_in_message(x, users_map))\n",
    "        return mentioned_users_series\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve_user_in_message(message, users_map):\n",
    "        \"\"\"\n",
    "        Helper method for extract_mentions to determine whether message contains a mention\n",
    "        :param message:\n",
    "        :return: user_ind\n",
    "        \"\"\"\n",
    "        if not message:\n",
    "            return -1\n",
    "        DELIMITERS = [',', ':']\n",
    "        for delim in DELIMITERS:\n",
    "            potential_user = str(message).split(delim)[0]\n",
    "            if potential_user in users_map:\n",
    "                return users_map[potential_user]\n",
    "        return -1\n",
    "    @staticmethod\n",
    "    def clean_file(file_path):\n",
    "        #Load to dataframe\n",
    "        data = pd.read_csv(file_path, header = None, names = ['raw'], delimiter=\"\\t\")\n",
    "\n",
    "        data['file_ind'] = data.index.values\n",
    "        data['file_ind'] = data['file_ind'].astype(int)\n",
    "\n",
    "        # #Extract Timestamp\n",
    "        # data['timestamp'] = data['raw'].str.extract(FileCleaner.TIMESTAMP_PATTERN, expand=True)\n",
    "        # data.loc[data['timestamp'].isnull(), 'timestamp'] = \"System\"\n",
    "        data['timestamp'] = FileCleaner.extract_timestamp(data['raw'])\n",
    "\n",
    "        data['minutes'] = FileCleaner.convert_timestamp(data['timestamp'])\n",
    "        data['minutes'] = FileCleaner.convert_12_to_24(data['minutes'])\n",
    "\n",
    "        data['timestamp'] = data['timestamp'].fillna(\"System\")\n",
    "        data['user'] = FileCleaner.extract_user(data['raw'])\n",
    "\n",
    "        map_path = '../data/cleaned/users.csv'\n",
    "        data['user_ind'] = FileCleaner.map_user(data['user'], map_path)\n",
    "        user_map = FileCleaner.load_user_dict(map_path, id_to_txt=False)\n",
    "\n",
    "        data['message'] = data['raw'].str.extract(FileCleaner.MESSAGE_PATTERN, expand=True)\n",
    "        data['message'] = data['message'].str.strip()\n",
    "\n",
    "        data['mentions'] = FileCleaner.extract_mentions(data['message'], user_map)\n",
    "\n",
    "        #data['date'] = Path(filename).stem.split('_')[0]\n",
    "        temp_date = re.search(FileCleaner.DATE_PATTERN, file_path).group(1)\n",
    "        data['date'] = temp_date\n",
    "\n",
    "        data['uuid'] = data.apply(lambda row: FileCleaner.generate_uuid(row), axis=1)\n",
    "\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:2403: FutureWarning: Possible nested set at position 1\n",
      "  regex = re.compile(pat, flags=flags)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "# Set patterns\n",
    "timestamp_pattern = \"[[](\\d\\d:\\d\\d)[]]\"\n",
    "user_pattern = \"[[]\\d\\d:\\d\\d[]]\\s[<](.*?)[>]\"\n",
    "message_pattern = \".*[<].*[>](.*)\"\n",
    "date_pattern = \"(\\d\\d\\d\\d-\\d\\d-\\d\\d)\"\n",
    "# Get files\n",
    "\n",
    "# Train\n",
    "filepath = '../data/'\n",
    "subfolders = [\"train\", \"test\", \"dev\"]\n",
    "\n",
    "file_list = []\n",
    "raw_df_dict = {}\n",
    "annot_dict = {}\n",
    "for subfolder in subfolders:\n",
    "    filelist_ascii = g(filepath + subfolder + '/*ascii.txt')\n",
    "    #filelist_annot = g(filepath + subfolder + '/*annotation.txt')\n",
    "    for filename in filelist_ascii:\n",
    "        file_list.append(filename)\n",
    "        filename_annot = filename.replace('ascii', 'annotation')\n",
    "        data = pd.read_csv(filename, header = None, names = ['raw'], delimiter=\"\\t\")\n",
    "        data['timestamp'] = data['raw'].str.extract(timestamp_pattern, expand=True)\n",
    "        data.loc[data['timestamp'].isnull(), 'timestamp'] = \"System\"\n",
    "        data['user'] = data['raw'].str.extract(user_pattern, expand=True)\n",
    "        data.loc[data['user'].isnull(), 'user'] = \"System\"\n",
    "        data['message'] = data['raw'].str.extract(message_pattern, expand=True)\n",
    "        data['file_ind'] = data.index.values\n",
    "        data['file_ind'] = data['file_ind'].astype(int)\n",
    "        #data['date'] = Path(filename).stem.split('_')[0]\n",
    "        temp_date = re.search(date_pattern, filename).group(1)\n",
    "        data['date'] = temp_date\n",
    "        data['uuid'] = data.apply(lambda row: generate_uuid(row), axis=1)\n",
    "\n",
    "        raw_df_dict[temp_date] = data.copy()\n",
    "\n",
    "        annot_df = pd.read_csv(filename_annot, index_col=False, header=None, names=['parent', 'child'], delimiter=\"\\s\")\n",
    "        annot_df = pd.concat([annot_df, fill_missing_annots(annot_df)]).drop_duplicates()\n",
    "        annot_dict[temp_date] = annot_df\n",
    "        merged_data = pd.merge(data, annot_df, left_on='file_ind', right_on='child', how='left')\n",
    "\n",
    "        #merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']\n",
    "        merged_data = pd.merge(merged_data, merged_data[['file_ind', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['', '_parent'])\n",
    "        #merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']\n",
    "\n",
    "        merged_data.to_csv(filename + \"_annot.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filepath = '../data/'\n",
    "subfolders = [\"dev\", \"train\", \"test\"]\n",
    "\n",
    "file_list = []\n",
    "raw_df_dict = {}\n",
    "annot_dict = {}\n",
    "for subfolder in subfolders:\n",
    "    filelist_ascii = g(filepath + subfolder + '/*ascii.txt')\n",
    "    #filelist_annot = g(filepath + subfolder + '/*annotation.txt')\n",
    "    for filename in filelist_ascii:\n",
    "        file_list.append(filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#file_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'../data/dev\\\\2004-11-15_03.ascii.txt'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Daniel\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_list:\n",
    "    filename_annot = file_path.replace('ascii', 'annotation')\n",
    "    data = FileCleaner.clean_file(file_path)\n",
    "\n",
    "    annot_df = pd.read_csv(filename_annot, index_col=False, header=None, names=['parent', 'child'], delimiter=\"\\s\")\n",
    "    annot_df = pd.concat([annot_df, fill_missing_annots(annot_df)]).drop_duplicates()\n",
    "    #annot_dict[temp_date] = annot_df\n",
    "    merged_data = pd.merge(data, annot_df, left_on='file_ind', right_on='child', how='left')\n",
    "\n",
    "    #merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']\n",
    "    merged_data = pd.merge(merged_data, merged_data[['file_ind', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['', '_parent'])\n",
    "    #merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']\n",
    "\n",
    "    merged_data.to_csv(file_path + \"_annot.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw  file_ind timestamp  \\\n0                                   [21:16] <lestus> o/         0     21:16   \n1                    [21:16] <lordcirth> Guest21456, hi         1     21:16   \n2                [21:16] <explosive> lorddoskias1: nope         2     21:16   \n3     [21:16] <lorddoskias1> huhz, rather strange in...         3     21:16   \n4      [21:16] <Guest21456> I want to lean about Linux.         4     21:16   \n...                                                 ...       ...       ...   \n1512                          [13:34] <Xin> evening all      1495     13:34   \n1513  [13:34] <ikonia> jimbotux: that sort of makes ...      1496     13:34   \n1514  [13:35] <sveinse> ikonia: But why does ubuntu ...      1497     13:35   \n1515  [13:35] <ikonia> sveinse: yes, as some upstart...      1498     13:35   \n1516  [13:35] <jimbotux> ikonia, Could you explain w...      1499     13:35   \n\n      minutes          user  user_ind  \\\n0        1276        lestus      3017   \n1        1276     lordcirth      8265   \n2        1276     explosive     10529   \n3        1276  lorddoskias1      8911   \n4        1276    Guest21456      6507   \n...       ...           ...       ...   \n1512     1534           Xin      5754   \n1513     1534        ikonia      6068   \n1514     1535       sveinse       593   \n1515     1535        ikonia      6068   \n1516     1535      jimbotux      8102   \n\n                                                message  mentions        date  \\\n0                                                    o/        -1  2016-06-08   \n1                                        Guest21456, hi      6507  2016-06-08   \n2                                    lorddoskias1: nope      8911  2016-06-08   \n3                           huhz, rather strange indeed        -1  2016-06-08   \n4                           I want to lean about Linux.        -1  2016-06-08   \n...                                                 ...       ...         ...   \n1512                                        evening all        -1  2016-06-08   \n1513                 jimbotux: that sort of makes sense      8102  2016-06-08   \n1514  ikonia: But why does ubuntu maintain /etc/rc*....      6068  2016-06-08   \n1515  sveinse: yes, as some upstart scripts are wrapped       593  2016-06-08   \n1516  ikonia, Could you explain why please? Im scrat...      6068  2016-06-08   \n\n                                 uuid  parent   child  file_ind_parent  \\\n0           2016_06_08_21_16_lestus_0     NaN     NaN              NaN   \n1        2016_06_08_21_16_lordcirth_1     NaN     NaN              NaN   \n2        2016_06_08_21_16_explosive_2     NaN     NaN              NaN   \n3     2016_06_08_21_16_lorddoskias1_3     NaN     NaN              NaN   \n4       2016_06_08_21_16_Guest21456_4     NaN     NaN              NaN   \n...                               ...     ...     ...              ...   \n1512        2016_06_08_13_34_Xin_1495  1495.0  1495.0           1495.0   \n1513     2016_06_08_13_34_ikonia_1496  1489.0  1496.0           1489.0   \n1514    2016_06_08_13_35_sveinse_1497  1492.0  1497.0           1492.0   \n1515     2016_06_08_13_35_ikonia_1498  1497.0  1498.0           1497.0   \n1516   2016_06_08_13_35_jimbotux_1499  1496.0  1499.0           1496.0   \n\n                         uuid_parent  \n0                                NaN  \n1                                NaN  \n2                                NaN  \n3                                NaN  \n4                                NaN  \n...                              ...  \n1512       2016_06_08_13_34_Xin_1495  \n1513  2016_06_08_13_33_jimbotux_1489  \n1514    2016_06_08_13_34_ikonia_1492  \n1515   2016_06_08_13_35_sveinse_1497  \n1516    2016_06_08_13_34_ikonia_1496  \n\n[1517 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>file_ind</th>\n      <th>timestamp</th>\n      <th>minutes</th>\n      <th>user</th>\n      <th>user_ind</th>\n      <th>message</th>\n      <th>mentions</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[21:16] &lt;lestus&gt; o/</td>\n      <td>0</td>\n      <td>21:16</td>\n      <td>1276</td>\n      <td>lestus</td>\n      <td>3017</td>\n      <td>o/</td>\n      <td>-1</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_21_16_lestus_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[21:16] &lt;lordcirth&gt; Guest21456, hi</td>\n      <td>1</td>\n      <td>21:16</td>\n      <td>1276</td>\n      <td>lordcirth</td>\n      <td>8265</td>\n      <td>Guest21456, hi</td>\n      <td>6507</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_21_16_lordcirth_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[21:16] &lt;explosive&gt; lorddoskias1: nope</td>\n      <td>2</td>\n      <td>21:16</td>\n      <td>1276</td>\n      <td>explosive</td>\n      <td>10529</td>\n      <td>lorddoskias1: nope</td>\n      <td>8911</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_21_16_explosive_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[21:16] &lt;lorddoskias1&gt; huhz, rather strange in...</td>\n      <td>3</td>\n      <td>21:16</td>\n      <td>1276</td>\n      <td>lorddoskias1</td>\n      <td>8911</td>\n      <td>huhz, rather strange indeed</td>\n      <td>-1</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_21_16_lorddoskias1_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[21:16] &lt;Guest21456&gt; I want to lean about Linux.</td>\n      <td>4</td>\n      <td>21:16</td>\n      <td>1276</td>\n      <td>Guest21456</td>\n      <td>6507</td>\n      <td>I want to lean about Linux.</td>\n      <td>-1</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_21_16_Guest21456_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1512</th>\n      <td>[13:34] &lt;Xin&gt; evening all</td>\n      <td>1495</td>\n      <td>13:34</td>\n      <td>1534</td>\n      <td>Xin</td>\n      <td>5754</td>\n      <td>evening all</td>\n      <td>-1</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_13_34_Xin_1495</td>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>2016_06_08_13_34_Xin_1495</td>\n    </tr>\n    <tr>\n      <th>1513</th>\n      <td>[13:34] &lt;ikonia&gt; jimbotux: that sort of makes ...</td>\n      <td>1496</td>\n      <td>13:34</td>\n      <td>1534</td>\n      <td>ikonia</td>\n      <td>6068</td>\n      <td>jimbotux: that sort of makes sense</td>\n      <td>8102</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_13_34_ikonia_1496</td>\n      <td>1489.0</td>\n      <td>1496.0</td>\n      <td>1489.0</td>\n      <td>2016_06_08_13_33_jimbotux_1489</td>\n    </tr>\n    <tr>\n      <th>1514</th>\n      <td>[13:35] &lt;sveinse&gt; ikonia: But why does ubuntu ...</td>\n      <td>1497</td>\n      <td>13:35</td>\n      <td>1535</td>\n      <td>sveinse</td>\n      <td>593</td>\n      <td>ikonia: But why does ubuntu maintain /etc/rc*....</td>\n      <td>6068</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_13_35_sveinse_1497</td>\n      <td>1492.0</td>\n      <td>1497.0</td>\n      <td>1492.0</td>\n      <td>2016_06_08_13_34_ikonia_1492</td>\n    </tr>\n    <tr>\n      <th>1515</th>\n      <td>[13:35] &lt;ikonia&gt; sveinse: yes, as some upstart...</td>\n      <td>1498</td>\n      <td>13:35</td>\n      <td>1535</td>\n      <td>ikonia</td>\n      <td>6068</td>\n      <td>sveinse: yes, as some upstart scripts are wrapped</td>\n      <td>593</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_13_35_ikonia_1498</td>\n      <td>1497.0</td>\n      <td>1498.0</td>\n      <td>1497.0</td>\n      <td>2016_06_08_13_35_sveinse_1497</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>[13:35] &lt;jimbotux&gt; ikonia, Could you explain w...</td>\n      <td>1499</td>\n      <td>13:35</td>\n      <td>1535</td>\n      <td>jimbotux</td>\n      <td>8102</td>\n      <td>ikonia, Could you explain why please? Im scrat...</td>\n      <td>6068</td>\n      <td>2016-06-08</td>\n      <td>2016_06_08_13_35_jimbotux_1499</td>\n      <td>1496.0</td>\n      <td>1499.0</td>\n      <td>1496.0</td>\n      <td>2016_06_08_13_34_ikonia_1496</td>\n    </tr>\n  </tbody>\n</table>\n<p>1517 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0      -1\n1      -1\n2      -1\n3      -1\n4      -1\n       ..\n1512   -1\n1513   -1\n1514   -1\n1515   -1\n1516   -1\nName: message, Length: 1517, dtype: int64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_path = '../data/cleaned/users.csv'\n",
    "user_map = FileCleaner.load_user_dict(map_path, id_to_txt=False)\n",
    "FileCleaner.extract_mentions(merged_data['message'], user_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "' lorddoskias1: nope'"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.iloc[2]['message']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "     parent  child\n0       999   1000\n1      1000   1001\n2       995   1002\n3      1002   1003\n4      1002   1004\n..      ...    ...\n509    1497   1498\n510    1496   1499\n0       999    999\n2       995    995\n21      296    296\n\n[514 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>999</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>1001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>995</td>\n      <td>1002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1002</td>\n      <td>1003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1002</td>\n      <td>1004</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>1497</td>\n      <td>1498</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>1496</td>\n      <td>1499</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>999</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>995</td>\n      <td>995</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>296</td>\n      <td>296</td>\n    </tr>\n  </tbody>\n</table>\n<p>514 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "'../data/test\\\\2016-06-08_07.annotation.txt'"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_annot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['raw', 'timestamp', 'user', 'message', 'file_ind', 'date', 'uuid',\n       'parent', 'child', 'file_ind_parent', 'uuid_parent'], dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Train\n",
    "filepath = '../data/train'\n",
    "csvs_train = pd.DataFrame(g(filepath + '/*annot.csv'), columns=[\"path\"])\n",
    "#csvs_train[\"date\"] = csvs_train[\"path\"].str.extract(date_pattern, expand=True)\n",
    "\n",
    "# Test\n",
    "filepath = '../data/test'\n",
    "csvs_test = pd.DataFrame(g(filepath + '/*annot.csv'), columns=[\"path\"])\n",
    "#csvs_test[\"date\"] = csvs_test[\"path\"].str.extract(date_pattern, expand=True)\n",
    "\n",
    "\n",
    "# Dev\n",
    "filepath = '../data/dev'\n",
    "csvs_dev = pd.DataFrame(g(filepath + '/*annot.csv'), columns=[\"path\"])\n",
    "#csvs_dev[\"date\"] = csvs_dev[\"path\"].str.extract(date_pattern, expand=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Aggregate files\n",
    "rootfile = '../data/cleaned/'\n",
    "\n",
    "agg_train = pd.DataFrame()\n",
    "for i in range(len(csvs_train.path)):\n",
    "    data = pd.read_csv(csvs_train.path[i], header = 0, index_col=0)\n",
    "    # data['date'] = pd.Series([csvs_train.date[i] for x in range(len(data))])\n",
    "    agg_train = agg_train.append(data)\n",
    "agg_train.to_csv(rootfile + \"agg_train.csv\")\n",
    "\n",
    "agg_test = pd.DataFrame()\n",
    "for i in range(len(csvs_test.path)):\n",
    "    data = pd.read_csv(csvs_test.path[i], header = 0, index_col=0)\n",
    "    # data['date'] = pd.Series([csvs_test.date[i] for x in range(len(data))])\n",
    "    agg_test = agg_test.append(data)\n",
    "agg_test.to_csv(rootfile + \"agg_test.csv\")\n",
    "\n",
    "agg_dev = pd.DataFrame()\n",
    "for i in range(len(csvs_dev.path)):\n",
    "    data = pd.read_csv(csvs_dev.path[i], header = 0, index_col=0)\n",
    "    # data['date'] = pd.Series([csvs_dev.date[i] for x in range(len(data))])\n",
    "    agg_dev = agg_dev.append(data)\n",
    "agg_dev.to_csv(rootfile + \"agg_dev.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw  file_ind timestamp  \\\n0       [12:18] <|trey|> usual, quite stable though  :)         0     12:18   \n1     [12:18] <tweaked> HrdwrBoB: ok how many partit...         1     12:18   \n2     [12:18] <Matt|> |trey|, top in the list --> ub...         2     12:18   \n3                  [12:18] <usual> a few libs and media         3     12:18   \n4                     [12:18] <usual> maybe some others         4     12:18   \n...                                                 ...       ...       ...   \n1259          [21:57] <zacky83> who can help me on this      1245     21:57   \n1260  [21:57] <Mccallum1983> can anyone assist, when...      1246     21:57   \n1261  [21:57] <figure002> OerHeks: still makes no se...      1247     21:57   \n1262  [21:58] <figure002> zacky83: did you enable th...      1248     21:58   \n1263             [21:59] <Mccallum1983> can anyone help      1249     21:59   \n\n      minutes          user  user_ind  \\\n0         738        |trey|     10946   \n1         738       tweaked      1375   \n2         738         Matt|      6784   \n3         738         usual      7183   \n4         738         usual      7183   \n...       ...           ...       ...   \n1259     2037       zacky83     14168   \n1260     2037  Mccallum1983     12323   \n1261     2037     figure002      6694   \n1262     2038     figure002      6694   \n1263     2039  Mccallum1983     12323   \n\n                                                message  mentions        date  \\\n0                        usual, quite stable though  :)      7183  2004-11-15   \n1       HrdwrBoB: ok how many partitions should i make?      6814  2004-11-15   \n2                                        ubuntu servers        -1  2004-11-15   \n3                                  a few libs and media        -1  2004-11-15   \n4                                     maybe some others        -1  2004-11-15   \n...                                                 ...       ...         ...   \n1259                            who can help me on this        -1  2016-12-19   \n1260  can anyone assist, when i try to install bitco...        -1  2016-12-19   \n1261  OerHeks: still makes no sense to me why a daem...     15400  2016-12-19   \n1262                 zacky83: did you enable the jails?     14168  2016-12-19   \n1263                                    can anyone help        -1  2016-12-19   \n\n                                    uuid  parent   child  file_ind_parent  \\\n0              2004_11_15_12_18_|trey|_0     NaN     NaN              NaN   \n1             2004_11_15_12_18_tweaked_1     NaN     NaN              NaN   \n2               2004_11_15_12_18_Matt|_2     NaN     NaN              NaN   \n3               2004_11_15_12_18_usual_3     NaN     NaN              NaN   \n4               2004_11_15_12_18_usual_4     NaN     NaN              NaN   \n...                                  ...     ...     ...              ...   \n1259       2016_12_19_21_57_zacky83_1245  1244.0  1245.0           1244.0   \n1260  2016_12_19_21_57_Mccallum1983_1246  1246.0  1246.0           1246.0   \n1261     2016_12_19_21_57_figure002_1247  1242.0  1247.0           1242.0   \n1262     2016_12_19_21_58_figure002_1248  1244.0  1248.0           1244.0   \n1263  2016_12_19_21_59_Mccallum1983_1249  1246.0  1249.0           1246.0   \n\n                             uuid_parent  \n0                                    NaN  \n1                                    NaN  \n2                                    NaN  \n3                                    NaN  \n4                                    NaN  \n...                                  ...  \n1259       2016_12_19_21_57_zacky83_1244  \n1260  2016_12_19_21_57_Mccallum1983_1246  \n1261       2016_12_19_21_56_OerHeks_1242  \n1262       2016_12_19_21_57_zacky83_1244  \n1263  2016_12_19_21_57_Mccallum1983_1246  \n\n[12683 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>file_ind</th>\n      <th>timestamp</th>\n      <th>minutes</th>\n      <th>user</th>\n      <th>user_ind</th>\n      <th>message</th>\n      <th>mentions</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[12:18] &lt;|trey|&gt; usual, quite stable though  :)</td>\n      <td>0</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>|trey|</td>\n      <td>10946</td>\n      <td>usual, quite stable though  :)</td>\n      <td>7183</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_|trey|_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[12:18] &lt;tweaked&gt; HrdwrBoB: ok how many partit...</td>\n      <td>1</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>tweaked</td>\n      <td>1375</td>\n      <td>HrdwrBoB: ok how many partitions should i make?</td>\n      <td>6814</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_tweaked_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[12:18] &lt;Matt|&gt; |trey|, top in the list --&gt; ub...</td>\n      <td>2</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>Matt|</td>\n      <td>6784</td>\n      <td>ubuntu servers</td>\n      <td>-1</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_Matt|_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[12:18] &lt;usual&gt; a few libs and media</td>\n      <td>3</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>usual</td>\n      <td>7183</td>\n      <td>a few libs and media</td>\n      <td>-1</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_usual_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[12:18] &lt;usual&gt; maybe some others</td>\n      <td>4</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>usual</td>\n      <td>7183</td>\n      <td>maybe some others</td>\n      <td>-1</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_usual_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1259</th>\n      <td>[21:57] &lt;zacky83&gt; who can help me on this</td>\n      <td>1245</td>\n      <td>21:57</td>\n      <td>2037</td>\n      <td>zacky83</td>\n      <td>14168</td>\n      <td>who can help me on this</td>\n      <td>-1</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_zacky83_1245</td>\n      <td>1244.0</td>\n      <td>1245.0</td>\n      <td>1244.0</td>\n      <td>2016_12_19_21_57_zacky83_1244</td>\n    </tr>\n    <tr>\n      <th>1260</th>\n      <td>[21:57] &lt;Mccallum1983&gt; can anyone assist, when...</td>\n      <td>1246</td>\n      <td>21:57</td>\n      <td>2037</td>\n      <td>Mccallum1983</td>\n      <td>12323</td>\n      <td>can anyone assist, when i try to install bitco...</td>\n      <td>-1</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>[21:57] &lt;figure002&gt; OerHeks: still makes no se...</td>\n      <td>1247</td>\n      <td>21:57</td>\n      <td>2037</td>\n      <td>figure002</td>\n      <td>6694</td>\n      <td>OerHeks: still makes no sense to me why a daem...</td>\n      <td>15400</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_figure002_1247</td>\n      <td>1242.0</td>\n      <td>1247.0</td>\n      <td>1242.0</td>\n      <td>2016_12_19_21_56_OerHeks_1242</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>[21:58] &lt;figure002&gt; zacky83: did you enable th...</td>\n      <td>1248</td>\n      <td>21:58</td>\n      <td>2038</td>\n      <td>figure002</td>\n      <td>6694</td>\n      <td>zacky83: did you enable the jails?</td>\n      <td>14168</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_58_figure002_1248</td>\n      <td>1244.0</td>\n      <td>1248.0</td>\n      <td>1244.0</td>\n      <td>2016_12_19_21_57_zacky83_1244</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>[21:59] &lt;Mccallum1983&gt; can anyone help</td>\n      <td>1249</td>\n      <td>21:59</td>\n      <td>2039</td>\n      <td>Mccallum1983</td>\n      <td>12323</td>\n      <td>can anyone help</td>\n      <td>-1</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_59_Mccallum1983_1249</td>\n      <td>1246.0</td>\n      <td>1249.0</td>\n      <td>1246.0</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n    </tr>\n  </tbody>\n</table>\n<p>12683 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "#agg_dev\n",
    "# Remove command messages\n",
    "agg_dict = {\n",
    "    'dev': agg_dev,\n",
    "    'train': agg_train,\n",
    "    'test': agg_test\n",
    "}\n",
    "\n",
    "for key in agg_dict.keys():\n",
    "    agg_dict[key] = agg_dict[key][agg_dict[key]['timestamp'].notnull()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp  minutes  \\\n0       [12:18] <|trey|> usual, quite stable though  :)     12:18      738   \n1     [12:18] <tweaked> HrdwrBoB: ok how many partit...     12:18      738   \n2     [12:18] <Matt|> |trey|, top in the list --> ub...     12:18      738   \n3                  [12:18] <usual> a few libs and media     12:18      738   \n4                     [12:18] <usual> maybe some others     12:18      738   \n...                                                 ...       ...      ...   \n1259          [21:57] <zacky83> who can help me on this     21:57     1317   \n1260  [21:57] <Mccallum1983> can anyone assist, when...     21:57     1317   \n1261  [21:57] <figure002> OerHeks: still makes no se...     21:57     1317   \n1262  [21:58] <figure002> zacky83: did you enable th...     21:58     1318   \n1263             [21:59] <Mccallum1983> can anyone help     21:59     1319   \n\n              user  user_ind  \\\n0           |trey|     10946   \n1          tweaked      1375   \n2            Matt|      6784   \n3            usual      7183   \n4            usual      7183   \n...            ...       ...   \n1259       zacky83     14168   \n1260  Mccallum1983     12323   \n1261     figure002      6694   \n1262     figure002      6694   \n1263  Mccallum1983     12323   \n\n                                                message  file_ind        date  \\\n0                        usual, quite stable though  :)         0  2004-11-15   \n1       HrdwrBoB: ok how many partitions should i make?         1  2004-11-15   \n2                                        ubuntu servers         2  2004-11-15   \n3                                  a few libs and media         3  2004-11-15   \n4                                     maybe some others         4  2004-11-15   \n...                                                 ...       ...         ...   \n1259                            who can help me on this      1245  2016-12-19   \n1260   can anyone assist, when i try to install bitc...      1246  2016-12-19   \n1261   OerHeks: still makes no sense to me why a dae...      1247  2016-12-19   \n1262                 zacky83: did you enable the jails?      1248  2016-12-19   \n1263                                    can anyone help      1249  2016-12-19   \n\n                                    uuid  parent   child  file_ind_parent  \\\n0              2004_11_15_12_18_|trey|_0     NaN     NaN              NaN   \n1             2004_11_15_12_18_tweaked_1     NaN     NaN              NaN   \n2               2004_11_15_12_18_Matt|_2     NaN     NaN              NaN   \n3               2004_11_15_12_18_usual_3     NaN     NaN              NaN   \n4               2004_11_15_12_18_usual_4     NaN     NaN              NaN   \n...                                  ...     ...     ...              ...   \n1259       2016_12_19_21_57_zacky83_1245  1244.0  1245.0           1244.0   \n1260  2016_12_19_21_57_Mccallum1983_1246  1246.0  1246.0           1246.0   \n1261     2016_12_19_21_57_figure002_1247  1242.0  1247.0           1242.0   \n1262     2016_12_19_21_58_figure002_1248  1244.0  1248.0           1244.0   \n1263  2016_12_19_21_59_Mccallum1983_1249  1246.0  1249.0           1246.0   \n\n                             uuid_parent  \n0                                    NaN  \n1                                    NaN  \n2                                    NaN  \n3                                    NaN  \n4                                    NaN  \n...                                  ...  \n1259       2016_12_19_21_57_zacky83_1244  \n1260  2016_12_19_21_57_Mccallum1983_1246  \n1261       2016_12_19_21_56_OerHeks_1242  \n1262       2016_12_19_21_57_zacky83_1244  \n1263  2016_12_19_21_57_Mccallum1983_1246  \n\n[12640 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>minutes</th>\n      <th>user</th>\n      <th>user_ind</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[12:18] &lt;|trey|&gt; usual, quite stable though  :)</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>|trey|</td>\n      <td>10946</td>\n      <td>usual, quite stable though  :)</td>\n      <td>0</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_|trey|_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[12:18] &lt;tweaked&gt; HrdwrBoB: ok how many partit...</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>tweaked</td>\n      <td>1375</td>\n      <td>HrdwrBoB: ok how many partitions should i make?</td>\n      <td>1</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_tweaked_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[12:18] &lt;Matt|&gt; |trey|, top in the list --&gt; ub...</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>Matt|</td>\n      <td>6784</td>\n      <td>ubuntu servers</td>\n      <td>2</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_Matt|_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[12:18] &lt;usual&gt; a few libs and media</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>usual</td>\n      <td>7183</td>\n      <td>a few libs and media</td>\n      <td>3</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_usual_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[12:18] &lt;usual&gt; maybe some others</td>\n      <td>12:18</td>\n      <td>738</td>\n      <td>usual</td>\n      <td>7183</td>\n      <td>maybe some others</td>\n      <td>4</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_12_18_usual_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1259</th>\n      <td>[21:57] &lt;zacky83&gt; who can help me on this</td>\n      <td>21:57</td>\n      <td>1317</td>\n      <td>zacky83</td>\n      <td>14168</td>\n      <td>who can help me on this</td>\n      <td>1245</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_zacky83_1245</td>\n      <td>1244.0</td>\n      <td>1245.0</td>\n      <td>1244.0</td>\n      <td>2016_12_19_21_57_zacky83_1244</td>\n    </tr>\n    <tr>\n      <th>1260</th>\n      <td>[21:57] &lt;Mccallum1983&gt; can anyone assist, when...</td>\n      <td>21:57</td>\n      <td>1317</td>\n      <td>Mccallum1983</td>\n      <td>12323</td>\n      <td>can anyone assist, when i try to install bitc...</td>\n      <td>1246</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>[21:57] &lt;figure002&gt; OerHeks: still makes no se...</td>\n      <td>21:57</td>\n      <td>1317</td>\n      <td>figure002</td>\n      <td>6694</td>\n      <td>OerHeks: still makes no sense to me why a dae...</td>\n      <td>1247</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_figure002_1247</td>\n      <td>1242.0</td>\n      <td>1247.0</td>\n      <td>1242.0</td>\n      <td>2016_12_19_21_56_OerHeks_1242</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>[21:58] &lt;figure002&gt; zacky83: did you enable th...</td>\n      <td>21:58</td>\n      <td>1318</td>\n      <td>figure002</td>\n      <td>6694</td>\n      <td>zacky83: did you enable the jails?</td>\n      <td>1248</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_58_figure002_1248</td>\n      <td>1244.0</td>\n      <td>1248.0</td>\n      <td>1244.0</td>\n      <td>2016_12_19_21_57_zacky83_1244</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>[21:59] &lt;Mccallum1983&gt; can anyone help</td>\n      <td>21:59</td>\n      <td>1319</td>\n      <td>Mccallum1983</td>\n      <td>12323</td>\n      <td>can anyone help</td>\n      <td>1249</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_59_Mccallum1983_1249</td>\n      <td>1246.0</td>\n      <td>1249.0</td>\n      <td>1246.0</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n    </tr>\n  </tbody>\n</table>\n<p>12640 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dict['dev']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# for key in agg_dict.keys():\n",
    "#     agg_dict[key]['uuid'] = agg_dict[key].apply(lambda row: generate_uuid(row), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   raw timestamp      user  \\\n685  [01:35] <djtansey> i have a problem re: k3b an...     01:35  djtansey   \n\n                                               message  file_ind        date  \\\n685   i have a problem re: k3b and am looking for s...       685  2004-11-15   \n\n                              uuid  parent  child  file_ind_parent  \\\n685  2004_11_15_01_35_djtansey_685   685.0  685.0            685.0   \n\n                       uuid_parent  \n685  2004_11_15_01_35_djtansey_685  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>685</th>\n      <td>[01:35] &lt;djtansey&gt; i have a problem re: k3b an...</td>\n      <td>01:35</td>\n      <td>djtansey</td>\n      <td>i have a problem re: k3b and am looking for s...</td>\n      <td>685</td>\n      <td>2004-11-15</td>\n      <td>2004_11_15_01_35_djtansey_685</td>\n      <td>685.0</td>\n      <td>685.0</td>\n      <td>685.0</td>\n      <td>2004_11_15_01_35_djtansey_685</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dict['dev'][agg_dict['dev']['uuid'] == \"2004_11_15_01_35_djtansey_685\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "for key in agg_dict.keys():\n",
    "    agg_dict[key].to_csv(rootfile + f\"data/cleaned/agg_{key}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data = raw_df_dict['2005-07-06']\n",
    "annot_df = annot_dict['2005-07-06']\n",
    "annot_df = pd.concat([annot_df, fill_missing_annots(annot_df)], ignore_index=True).drop_duplicates()\n",
    "merged_data = pd.merge(data, annot_df, left_on='file_ind', right_on='child', how='left')\n",
    "\n",
    "#merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']\n",
    "merged_data = pd.merge(merged_data, merged_data[['file_ind', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['', '_parent'])\n",
    "#merged_data.to_csv(filename + \"_annot.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      parent  file_ind                        uuid\n0        NaN       NaN                         NaN\n1        NaN       NaN                         NaN\n2        NaN       NaN                         NaN\n3        NaN       NaN                         NaN\n4        NaN       NaN                         NaN\n...      ...       ...                         ...\n1516  1493.0    1493.0  2005_07_06_03_35_Nige_1493\n1517  1495.0    1495.0  2005_07_06_03_35_Nige_1495\n1518  1495.0    1495.0  2005_07_06_03_35_Nige_1495\n1519  1498.0    1498.0   2005_07_06_03_35_FLD_1498\n1520  1494.0    1494.0  2005_07_06_03_35_wizo_1494\n\n[1521 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>file_ind</th>\n      <th>uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>1493.0</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1493</td>\n    </tr>\n    <tr>\n      <th>1517</th>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1518</th>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1519</th>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>1494.0</td>\n      <td>1494.0</td>\n      <td>2005_07_06_03_35_wizo_1494</td>\n    </tr>\n  </tbody>\n</table>\n<p>1521 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.merge(merged_data[['parent']], merged_data[['file_ind', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, merged_data[['file_ind', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['', '_parent'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp       user  \\\n0     [11:11] <Seveas> Amaranth, the US peer is prob...     11:11     Seveas   \n1     [11:11] <Seveas> but an ES or NL peer download...     11:11     Seveas   \n2     [11:11] <monchichi> http://www.msnbc.msn.com/i...     11:11  monchichi   \n3     [11:11] <IceDC571> the US peer is just stupid ...     11:11   IceDC571   \n4     [11:11] <Seveas> The downloader is breaking th...     11:11     Seveas   \n...                                                 ...       ...        ...   \n1516  [03:35] <Nige> i am stuck with wireless networ...     03:35       Nige   \n1517                                  [03:35] <Nige> :(     03:35       Nige   \n1518         [03:35] <Nige> and its driving me crazy!!!     03:35       Nige   \n1519  [03:35] <FLD> does anybody know how to get dsn...     03:35        FLD   \n1520                               [03:35] <iLLf8d> heh     03:35     iLLf8d   \n\n                                                message  file_ind        date  \\\n0      Amaranth, the US peer is probably breaking th...         0  2005-07-06   \n1               but an ES or NL peer downloading it not         1  2005-07-06   \n2                  http://www.msnbc.msn.com/id/8419601/         2  2005-07-06   \n3      the US peer is just stupid for wanting to sha...         3  2005-07-06   \n4      The downloader is breaking the implicit rules...         4  2005-07-06   \n...                                                 ...       ...         ...   \n1516                i am stuck with wireless networking      1495  2005-07-06   \n1517                                                 :(      1496  2005-07-06   \n1518                        and its driving me crazy!!!      1497  2005-07-06   \n1519     does anybody know how to get dsniff to work :<      1498  2005-07-06   \n1520                                                heh      1499  2005-07-06   \n\n                              uuid  parent   child  file_ind_parent  \\\n0        2005_07_06_11_11_Seveas_0     NaN     NaN              NaN   \n1        2005_07_06_11_11_Seveas_1     NaN     NaN              NaN   \n2     2005_07_06_11_11_monchichi_2     NaN     NaN              NaN   \n3      2005_07_06_11_11_IceDC571_3     NaN     NaN              NaN   \n4        2005_07_06_11_11_Seveas_4     NaN     NaN              NaN   \n...                            ...     ...     ...              ...   \n1516    2005_07_06_03_35_Nige_1495  1493.0  1495.0           1493.0   \n1517    2005_07_06_03_35_Nige_1496  1495.0  1496.0           1495.0   \n1518    2005_07_06_03_35_Nige_1497  1495.0  1497.0           1495.0   \n1519     2005_07_06_03_35_FLD_1498  1498.0  1498.0           1498.0   \n1520  2005_07_06_03_35_iLLf8d_1499  1494.0  1499.0           1494.0   \n\n                     uuid_parent  file_ind_parent                 uuid_parent  \n0                            NaN              NaN                         NaN  \n1                            NaN              NaN                         NaN  \n2                            NaN              NaN                         NaN  \n3                            NaN              NaN                         NaN  \n4                            NaN              NaN                         NaN  \n...                          ...              ...                         ...  \n1516  2005_07_06_03_35_Nige_1493           1493.0  2005_07_06_03_35_Nige_1493  \n1517  2005_07_06_03_35_Nige_1495           1495.0  2005_07_06_03_35_Nige_1495  \n1518  2005_07_06_03_35_Nige_1495           1495.0  2005_07_06_03_35_Nige_1495  \n1519   2005_07_06_03_35_FLD_1498           1498.0   2005_07_06_03_35_FLD_1498  \n1520  2005_07_06_03_35_wizo_1494           1494.0  2005_07_06_03_35_wizo_1494  \n\n[1521 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n      <th>file_ind_parent</th>\n      <th>uuid_parent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[11:11] &lt;Seveas&gt; Amaranth, the US peer is prob...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>Amaranth, the US peer is probably breaking th...</td>\n      <td>0</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[11:11] &lt;Seveas&gt; but an ES or NL peer download...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>but an ES or NL peer downloading it not</td>\n      <td>1</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[11:11] &lt;monchichi&gt; http://www.msnbc.msn.com/i...</td>\n      <td>11:11</td>\n      <td>monchichi</td>\n      <td>http://www.msnbc.msn.com/id/8419601/</td>\n      <td>2</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_monchichi_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[11:11] &lt;IceDC571&gt; the US peer is just stupid ...</td>\n      <td>11:11</td>\n      <td>IceDC571</td>\n      <td>the US peer is just stupid for wanting to sha...</td>\n      <td>3</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_IceDC571_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[11:11] &lt;Seveas&gt; The downloader is breaking th...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>The downloader is breaking the implicit rules...</td>\n      <td>4</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>[03:35] &lt;Nige&gt; i am stuck with wireless networ...</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>i am stuck with wireless networking</td>\n      <td>1495</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1493.0</td>\n      <td>1495.0</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1493</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1493</td>\n    </tr>\n    <tr>\n      <th>1517</th>\n      <td>[03:35] &lt;Nige&gt; :(</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>:(</td>\n      <td>1496</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1496</td>\n      <td>1495.0</td>\n      <td>1496.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1518</th>\n      <td>[03:35] &lt;Nige&gt; and its driving me crazy!!!</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>and its driving me crazy!!!</td>\n      <td>1497</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1497</td>\n      <td>1495.0</td>\n      <td>1497.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1519</th>\n      <td>[03:35] &lt;FLD&gt; does anybody know how to get dsn...</td>\n      <td>03:35</td>\n      <td>FLD</td>\n      <td>does anybody know how to get dsniff to work :&lt;</td>\n      <td>1498</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>[03:35] &lt;iLLf8d&gt; heh</td>\n      <td>03:35</td>\n      <td>iLLf8d</td>\n      <td>heh</td>\n      <td>1499</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_iLLf8d_1499</td>\n      <td>1494.0</td>\n      <td>1499.0</td>\n      <td>1494.0</td>\n      <td>2005_07_06_03_35_wizo_1494</td>\n      <td>1494.0</td>\n      <td>2005_07_06_03_35_wizo_1494</td>\n    </tr>\n  </tbody>\n</table>\n<p>1521 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     parent  child\n0       993   1000\n1       995   1000\n2      1001   1001\n3      1000   1002\n4       998   1003\n..      ...    ...\n504    1498   1498\n505    1494   1499\n506     993    993\n507     995    995\n508     998    998\n\n[509 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>993</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>995</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001</td>\n      <td>1001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>1002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>998</td>\n      <td>1003</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>1498</td>\n      <td>1498</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>1494</td>\n      <td>1499</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>993</td>\n      <td>993</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>995</td>\n      <td>995</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>998</td>\n      <td>998</td>\n    </tr>\n  </tbody>\n</table>\n<p>509 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "     parent  child\n265    1254   1262",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>265</th>\n      <td>1254</td>\n      <td>1262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df[annot_df['child']==1262]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp  user  \\\n1262  [02:59] <Vjaz> delire, Yeah, I'm no stranger t...     02:59  Vjaz   \n\n                                                message  file_ind        date  \\\n1262   delire, Yeah, I'm no stranger to compiling my...      1262  2005-07-06   \n\n                            uuid  \n1262  2005_07_06_02_59_Vjaz_1262  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1262</th>\n      <td>[02:59] &lt;Vjaz&gt; delire, Yeah, I'm no stranger t...</td>\n      <td>02:59</td>\n      <td>Vjaz</td>\n      <td>delire, Yeah, I'm no stranger to compiling my...</td>\n      <td>1262</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_02_59_Vjaz_1262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['file_ind'] == 1262]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp       user  \\\n0     [11:11] <Seveas> Amaranth, the US peer is prob...     11:11     Seveas   \n1     [11:11] <Seveas> but an ES or NL peer download...     11:11     Seveas   \n2     [11:11] <monchichi> http://www.msnbc.msn.com/i...     11:11  monchichi   \n3     [11:11] <IceDC571> the US peer is just stupid ...     11:11   IceDC571   \n4     [11:11] <Seveas> The downloader is breaking th...     11:11     Seveas   \n...                                                 ...       ...        ...   \n1201  [03:35] <Nige> i am stuck with wireless networ...     03:35       Nige   \n1202                                  [03:35] <Nige> :(     03:35       Nige   \n1203         [03:35] <Nige> and its driving me crazy!!!     03:35       Nige   \n1204  [03:35] <FLD> does anybody know how to get dsn...     03:35        FLD   \n1205                               [03:35] <iLLf8d> heh     03:35     iLLf8d   \n\n                                                message  file_ind        date  \\\n0      Amaranth, the US peer is probably breaking th...         0  2005-07-06   \n1               but an ES or NL peer downloading it not         1  2005-07-06   \n2                  http://www.msnbc.msn.com/id/8419601/         2  2005-07-06   \n3      the US peer is just stupid for wanting to sha...         3  2005-07-06   \n4      The downloader is breaking the implicit rules...         4  2005-07-06   \n...                                                 ...       ...         ...   \n1201                i am stuck with wireless networking      1495  2005-07-06   \n1202                                                 :(      1496  2005-07-06   \n1203                        and its driving me crazy!!!      1497  2005-07-06   \n1204     does anybody know how to get dsniff to work :<      1498  2005-07-06   \n1205                                                heh      1499  2005-07-06   \n\n                              uuid  parent   child  \n0        2005_07_06_11_11_Seveas_0     NaN     NaN  \n1        2005_07_06_11_11_Seveas_1     NaN     NaN  \n2     2005_07_06_11_11_monchichi_2     NaN     NaN  \n3      2005_07_06_11_11_IceDC571_3     NaN     NaN  \n4        2005_07_06_11_11_Seveas_4     NaN     NaN  \n...                            ...     ...     ...  \n1201    2005_07_06_03_35_Nige_1495  1493.0  1495.0  \n1202    2005_07_06_03_35_Nige_1496  1495.0  1496.0  \n1203    2005_07_06_03_35_Nige_1497  1495.0  1497.0  \n1204     2005_07_06_03_35_FLD_1498  1498.0  1498.0  \n1205  2005_07_06_03_35_iLLf8d_1499  1494.0  1499.0  \n\n[1206 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[11:11] &lt;Seveas&gt; Amaranth, the US peer is prob...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>Amaranth, the US peer is probably breaking th...</td>\n      <td>0</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[11:11] &lt;Seveas&gt; but an ES or NL peer download...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>but an ES or NL peer downloading it not</td>\n      <td>1</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[11:11] &lt;monchichi&gt; http://www.msnbc.msn.com/i...</td>\n      <td>11:11</td>\n      <td>monchichi</td>\n      <td>http://www.msnbc.msn.com/id/8419601/</td>\n      <td>2</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_monchichi_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[11:11] &lt;IceDC571&gt; the US peer is just stupid ...</td>\n      <td>11:11</td>\n      <td>IceDC571</td>\n      <td>the US peer is just stupid for wanting to sha...</td>\n      <td>3</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_IceDC571_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[11:11] &lt;Seveas&gt; The downloader is breaking th...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>The downloader is breaking the implicit rules...</td>\n      <td>4</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>[03:35] &lt;Nige&gt; i am stuck with wireless networ...</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>i am stuck with wireless networking</td>\n      <td>1495</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1493.0</td>\n      <td>1495.0</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>[03:35] &lt;Nige&gt; :(</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>:(</td>\n      <td>1496</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1496</td>\n      <td>1495.0</td>\n      <td>1496.0</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>[03:35] &lt;Nige&gt; and its driving me crazy!!!</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>and its driving me crazy!!!</td>\n      <td>1497</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1497</td>\n      <td>1495.0</td>\n      <td>1497.0</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>[03:35] &lt;FLD&gt; does anybody know how to get dsn...</td>\n      <td>03:35</td>\n      <td>FLD</td>\n      <td>does anybody know how to get dsniff to work :&lt;</td>\n      <td>1498</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>[03:35] &lt;iLLf8d&gt; heh</td>\n      <td>03:35</td>\n      <td>iLLf8d</td>\n      <td>heh</td>\n      <td>1499</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_iLLf8d_1499</td>\n      <td>1494.0</td>\n      <td>1499.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1206 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.merge(data, annot_df, left_on='file_ind', right_on='child', how='left')\n",
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp  \\\n0     [04:14] <Gobbert> ziggi: what do you need help...     04:14   \n1                                  [04:14] <ziggi> i am     04:14   \n2           [04:15] <joshua__> boot speed was very slow     04:15   \n3                      [04:15] <joshua__> 2 min to boot     04:15   \n4     [04:15] <joshua__> but windows machine was ver...     04:15   \n...                                                 ...       ...   \n1205          [21:57] <zacky83> who can help me on this     21:57   \n1206  [21:57] <Mccallum1983> can anyone assist, when...     21:57   \n1207  [21:57] <figure002> OerHeks: still makes no se...     21:57   \n1208  [21:58] <figure002> zacky83: did you enable th...     21:58   \n1209             [21:59] <Mccallum1983> can anyone help     21:59   \n\n              user                                            message  \\\n0          Gobbert                 ziggi: what do you need help with?   \n1            ziggi                                               i am   \n2         joshua__                           boot speed was very slow   \n3         joshua__                                      2 min to boot   \n4         joshua__                  but windows machine was very fast   \n...            ...                                                ...   \n1205       zacky83                            who can help me on this   \n1206  Mccallum1983   can anyone assist, when i try to install bitc...   \n1207     figure002   OerHeks: still makes no sense to me why a dae...   \n1208     figure002                 zacky83: did you enable the jails?   \n1209  Mccallum1983                                    can anyone help   \n\n      file_ind        date                                uuid  parent_x  \\\n0            0  2016-12-19          2016_12_19_04_14_Gobbert_0       NaN   \n1            1  2016-12-19            2016_12_19_04_14_ziggi_1       NaN   \n2            2  2016-12-19         2016_12_19_04_15_joshua___2       NaN   \n3            3  2016-12-19         2016_12_19_04_15_joshua___3       NaN   \n4            4  2016-12-19         2016_12_19_04_15_joshua___4       NaN   \n...        ...         ...                                 ...       ...   \n1205      1245  2016-12-19       2016_12_19_21_57_zacky83_1245    1244.0   \n1206      1246  2016-12-19  2016_12_19_21_57_Mccallum1983_1246    1246.0   \n1207      1247  2016-12-19     2016_12_19_21_57_figure002_1247    1242.0   \n1208      1248  2016-12-19     2016_12_19_21_58_figure002_1248    1244.0   \n1209      1249  2016-12-19  2016_12_19_21_59_Mccallum1983_1249    1246.0   \n\n      child_x                       parent_uuid  parent_y  child_y  \n0         NaN                               NaN       NaN      NaN  \n1         NaN                               NaN       NaN      NaN  \n2         NaN                               NaN       NaN      NaN  \n3         NaN                               NaN       NaN      NaN  \n4         NaN                               NaN       NaN      NaN  \n...       ...                               ...       ...      ...  \n1205   1245.0  2016_12_19_21_55_zh19970205_1239    1244.0   1245.0  \n1206   1246.0  2016_12_19_21_55_zh19970205_1239    1246.0   1246.0  \n1207   1247.0  2016_12_19_21_55_zh19970205_1240    1242.0   1247.0  \n1208   1248.0   2016_12_19_21_52_figure002_1231    1244.0   1248.0  \n1209   1249.0  2016_12_19_21_55_zh19970205_1241    1246.0   1249.0  \n\n[1210 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent_x</th>\n      <th>child_x</th>\n      <th>parent_uuid</th>\n      <th>parent_y</th>\n      <th>child_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[04:14] &lt;Gobbert&gt; ziggi: what do you need help...</td>\n      <td>04:14</td>\n      <td>Gobbert</td>\n      <td>ziggi: what do you need help with?</td>\n      <td>0</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_04_14_Gobbert_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[04:14] &lt;ziggi&gt; i am</td>\n      <td>04:14</td>\n      <td>ziggi</td>\n      <td>i am</td>\n      <td>1</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_04_14_ziggi_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[04:15] &lt;joshua__&gt; boot speed was very slow</td>\n      <td>04:15</td>\n      <td>joshua__</td>\n      <td>boot speed was very slow</td>\n      <td>2</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_04_15_joshua___2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[04:15] &lt;joshua__&gt; 2 min to boot</td>\n      <td>04:15</td>\n      <td>joshua__</td>\n      <td>2 min to boot</td>\n      <td>3</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_04_15_joshua___3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[04:15] &lt;joshua__&gt; but windows machine was ver...</td>\n      <td>04:15</td>\n      <td>joshua__</td>\n      <td>but windows machine was very fast</td>\n      <td>4</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_04_15_joshua___4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>[21:57] &lt;zacky83&gt; who can help me on this</td>\n      <td>21:57</td>\n      <td>zacky83</td>\n      <td>who can help me on this</td>\n      <td>1245</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_zacky83_1245</td>\n      <td>1244.0</td>\n      <td>1245.0</td>\n      <td>2016_12_19_21_55_zh19970205_1239</td>\n      <td>1244.0</td>\n      <td>1245.0</td>\n    </tr>\n    <tr>\n      <th>1206</th>\n      <td>[21:57] &lt;Mccallum1983&gt; can anyone assist, when...</td>\n      <td>21:57</td>\n      <td>Mccallum1983</td>\n      <td>can anyone assist, when i try to install bitc...</td>\n      <td>1246</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_Mccallum1983_1246</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n      <td>2016_12_19_21_55_zh19970205_1239</td>\n      <td>1246.0</td>\n      <td>1246.0</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>[21:57] &lt;figure002&gt; OerHeks: still makes no se...</td>\n      <td>21:57</td>\n      <td>figure002</td>\n      <td>OerHeks: still makes no sense to me why a dae...</td>\n      <td>1247</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_57_figure002_1247</td>\n      <td>1242.0</td>\n      <td>1247.0</td>\n      <td>2016_12_19_21_55_zh19970205_1240</td>\n      <td>1242.0</td>\n      <td>1247.0</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>[21:58] &lt;figure002&gt; zacky83: did you enable th...</td>\n      <td>21:58</td>\n      <td>figure002</td>\n      <td>zacky83: did you enable the jails?</td>\n      <td>1248</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_58_figure002_1248</td>\n      <td>1244.0</td>\n      <td>1248.0</td>\n      <td>2016_12_19_21_52_figure002_1231</td>\n      <td>1244.0</td>\n      <td>1248.0</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>[21:59] &lt;Mccallum1983&gt; can anyone help</td>\n      <td>21:59</td>\n      <td>Mccallum1983</td>\n      <td>can anyone help</td>\n      <td>1249</td>\n      <td>2016-12-19</td>\n      <td>2016_12_19_21_59_Mccallum1983_1249</td>\n      <td>1246.0</td>\n      <td>1249.0</td>\n      <td>2016_12_19_21_55_zh19970205_1241</td>\n      <td>1246.0</td>\n      <td>1249.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1210 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp  user  \\\n1019  [02:59] <Vjaz> delire, Yeah, I'm no stranger t...     02:59  Vjaz   \n\n                                                message  file_ind        date  \\\n1019   delire, Yeah, I'm no stranger to compiling my...      1262  2005-07-06   \n\n                            uuid  parent   child  \n1019  2005_07_06_02_59_Vjaz_1262  1254.0  1262.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1019</th>\n      <td>[02:59] &lt;Vjaz&gt; delire, Yeah, I'm no stranger t...</td>\n      <td>02:59</td>\n      <td>Vjaz</td>\n      <td>delire, Yeah, I'm no stranger to compiling my...</td>\n      <td>1262</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_02_59_Vjaz_1262</td>\n      <td>1254.0</td>\n      <td>1262.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[merged_data['child'] == 1262]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp    user  \\\n1022  [03:00] <delire> Vjaz: it is a little. i think...     03:00  delire   \n\n                                                message  file_ind        date  \\\n1022   Vjaz: it is a little. i think the best approa...      1265  2005-07-06   \n\n                              uuid  parent   child  \n1022  2005_07_06_03_00_delire_1265  1262.0  1265.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1022</th>\n      <td>[03:00] &lt;delire&gt; Vjaz: it is a little. i think...</td>\n      <td>03:00</td>\n      <td>delire</td>\n      <td>Vjaz: it is a little. i think the best approa...</td>\n      <td>1265</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_00_delire_1265</td>\n      <td>1262.0</td>\n      <td>1265.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[merged_data['parent'] == 1262]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw timestamp       user  \\\n0     [11:11] <Seveas> Amaranth, the US peer is prob...     11:11     Seveas   \n1     [11:11] <Seveas> but an ES or NL peer download...     11:11     Seveas   \n2     [11:11] <monchichi> http://www.msnbc.msn.com/i...     11:11  monchichi   \n3     [11:11] <IceDC571> the US peer is just stupid ...     11:11   IceDC571   \n4     [11:11] <Seveas> The downloader is breaking th...     11:11     Seveas   \n...                                                 ...       ...        ...   \n1201  [03:35] <Nige> i am stuck with wireless networ...     03:35       Nige   \n1202                                  [03:35] <Nige> :(     03:35       Nige   \n1203         [03:35] <Nige> and its driving me crazy!!!     03:35       Nige   \n1204  [03:35] <FLD> does anybody know how to get dsn...     03:35        FLD   \n1205                               [03:35] <iLLf8d> heh     03:35     iLLf8d   \n\n                                                message  file_ind        date  \\\n0      Amaranth, the US peer is probably breaking th...         0  2005-07-06   \n1               but an ES or NL peer downloading it not         1  2005-07-06   \n2                  http://www.msnbc.msn.com/id/8419601/         2  2005-07-06   \n3      the US peer is just stupid for wanting to sha...         3  2005-07-06   \n4      The downloader is breaking the implicit rules...         4  2005-07-06   \n...                                                 ...       ...         ...   \n1201                i am stuck with wireless networking      1495  2005-07-06   \n1202                                                 :(      1496  2005-07-06   \n1203                        and its driving me crazy!!!      1497  2005-07-06   \n1204     does anybody know how to get dsniff to work :<      1498  2005-07-06   \n1205                                                heh      1499  2005-07-06   \n\n                              uuid  parent   child  \n0        2005_07_06_11_11_Seveas_0     NaN     NaN  \n1        2005_07_06_11_11_Seveas_1     NaN     NaN  \n2     2005_07_06_11_11_monchichi_2     NaN     NaN  \n3      2005_07_06_11_11_IceDC571_3     NaN     NaN  \n4        2005_07_06_11_11_Seveas_4     NaN     NaN  \n...                            ...     ...     ...  \n1201    2005_07_06_03_35_Nige_1495  1493.0  1495.0  \n1202    2005_07_06_03_35_Nige_1496  1495.0  1496.0  \n1203    2005_07_06_03_35_Nige_1497  1495.0  1497.0  \n1204     2005_07_06_03_35_FLD_1498  1498.0  1498.0  \n1205  2005_07_06_03_35_iLLf8d_1499  1494.0  1499.0  \n\n[1206 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>timestamp</th>\n      <th>user</th>\n      <th>message</th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[11:11] &lt;Seveas&gt; Amaranth, the US peer is prob...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>Amaranth, the US peer is probably breaking th...</td>\n      <td>0</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[11:11] &lt;Seveas&gt; but an ES or NL peer download...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>but an ES or NL peer downloading it not</td>\n      <td>1</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[11:11] &lt;monchichi&gt; http://www.msnbc.msn.com/i...</td>\n      <td>11:11</td>\n      <td>monchichi</td>\n      <td>http://www.msnbc.msn.com/id/8419601/</td>\n      <td>2</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_monchichi_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[11:11] &lt;IceDC571&gt; the US peer is just stupid ...</td>\n      <td>11:11</td>\n      <td>IceDC571</td>\n      <td>the US peer is just stupid for wanting to sha...</td>\n      <td>3</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_IceDC571_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[11:11] &lt;Seveas&gt; The downloader is breaking th...</td>\n      <td>11:11</td>\n      <td>Seveas</td>\n      <td>The downloader is breaking the implicit rules...</td>\n      <td>4</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>[03:35] &lt;Nige&gt; i am stuck with wireless networ...</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>i am stuck with wireless networking</td>\n      <td>1495</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1493.0</td>\n      <td>1495.0</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>[03:35] &lt;Nige&gt; :(</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>:(</td>\n      <td>1496</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1496</td>\n      <td>1495.0</td>\n      <td>1496.0</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>[03:35] &lt;Nige&gt; and its driving me crazy!!!</td>\n      <td>03:35</td>\n      <td>Nige</td>\n      <td>and its driving me crazy!!!</td>\n      <td>1497</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1497</td>\n      <td>1495.0</td>\n      <td>1497.0</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>[03:35] &lt;FLD&gt; does anybody know how to get dsn...</td>\n      <td>03:35</td>\n      <td>FLD</td>\n      <td>does anybody know how to get dsniff to work :&lt;</td>\n      <td>1498</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>[03:35] &lt;iLLf8d&gt; heh</td>\n      <td>03:35</td>\n      <td>iLLf8d</td>\n      <td>heh</td>\n      <td>1499</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_iLLf8d_1499</td>\n      <td>1494.0</td>\n      <td>1499.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1206 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'System'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7964\\2275677173.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtime_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bfill'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtime_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtime_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'minutes_sum'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m60\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtime_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   5813\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5814\u001B[0m             \u001B[1;31m# else, only a single dtype is given\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5815\u001B[1;33m             \u001B[0mnew_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5816\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5817\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"raise\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 418\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    419\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    420\u001B[0m     def convert(\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    326\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 327\u001B[1;33m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    328\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mignore_failures\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    589\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    590\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_array_safe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    592\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmaybe_coerce_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_values\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   1307\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1308\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1309\u001B[1;33m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1310\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1311\u001B[0m         \u001B[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m   1255\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1256\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1257\u001B[1;33m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_nansafe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1258\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1259\u001B[0m     \u001B[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m   1172\u001B[0m         \u001B[1;31m# work around NumPy brokenness, #1987\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1173\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missubdtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minteger\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1174\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype_intsafe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1175\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1176\u001B[0m         \u001B[1;31m# if we have a datetime/timedelta array of objects\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.astype_intsafe\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'System'"
     ]
    }
   ],
   "source": [
    "time_df = merged_data['timestamp'].str.split(':', expand=True)\n",
    "time_df = time_df.fillna(method='bfill')\n",
    "time_df = time_df.fillna(-1)\n",
    "time_df['minutes_sum'] = time_df[0].astype(int) * 60 + time_df[1].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "temp = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r']).copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "      child_l  parent_l                      uuid_l  file_ind  child_r  \\\n1020   1262.0    1254.0  2005_07_06_02_59_Vjaz_1262    1254.0   1254.0   \n\n      parent_r                        uuid_r  \n1020    1252.0  2005_07_06_02_58_delire_1254  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>child_l</th>\n      <th>parent_l</th>\n      <th>uuid_l</th>\n      <th>file_ind</th>\n      <th>child_r</th>\n      <th>parent_r</th>\n      <th>uuid_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1020</th>\n      <td>1262.0</td>\n      <td>1254.0</td>\n      <td>2005_07_06_02_59_Vjaz_1262</td>\n      <td>1254.0</td>\n      <td>1254.0</td>\n      <td>1252.0</td>\n      <td>2005_07_06_02_58_delire_1254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp['child_l'] == 1262]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "merged_data['parent_uuid'] = pd.merge(merged_data[['child', 'parent', 'uuid']], merged_data[['file_ind', 'child', 'parent', 'uuid']], left_on='parent', right_on='file_ind', how='left', suffixes=['_l', '_r'])['uuid_r']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "      file_ind        date                          uuid  parent  \\\n0            0  2005-07-06     2005_07_06_11_11_Seveas_0     NaN   \n1            1  2005-07-06     2005_07_06_11_11_Seveas_1     NaN   \n2            2  2005-07-06  2005_07_06_11_11_monchichi_2     NaN   \n3            3  2005-07-06   2005_07_06_11_11_IceDC571_3     NaN   \n4            4  2005-07-06     2005_07_06_11_11_Seveas_4     NaN   \n...        ...         ...                           ...     ...   \n1201      1495  2005-07-06    2005_07_06_03_35_Nige_1495  1493.0   \n1202      1496  2005-07-06    2005_07_06_03_35_Nige_1496  1495.0   \n1203      1497  2005-07-06    2005_07_06_03_35_Nige_1497  1495.0   \n1204      1498  2005-07-06     2005_07_06_03_35_FLD_1498  1498.0   \n1205      1499  2005-07-06  2005_07_06_03_35_iLLf8d_1499  1494.0   \n\n                          parent_uuid  \n0                                 NaN  \n1                                 NaN  \n2                                 NaN  \n3                                 NaN  \n4                                 NaN  \n...                               ...  \n1201  2005_07_06_03_35_mindmedic_1490  \n1202        2005_07_06_03_35_fdr_1492  \n1203     2005_07_06_03_35_delire_1489  \n1204       2005_07_06_03_34_wizo_1487  \n1205       2005_07_06_03_35_Nige_1493  \n\n[1206 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ind</th>\n      <th>date</th>\n      <th>uuid</th>\n      <th>parent</th>\n      <th>parent_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_monchichi_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_IceDC571_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_11_11_Seveas_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>1495</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_mindmedic_1490</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>1496</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1496</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_fdr_1492</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>1497</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_Nige_1497</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_delire_1489</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>1498</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_34_wizo_1487</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>1499</td>\n      <td>2005-07-06</td>\n      <td>2005_07_06_03_35_iLLf8d_1499</td>\n      <td>1494.0</td>\n      <td>2005_07_06_03_35_Nige_1493</td>\n    </tr>\n  </tbody>\n</table>\n<p>1206 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[['file_ind', 'date', 'uuid', 'parent', 'parent_uuid']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "      child_l  parent_l                        uuid_l  file_ind  child_r  \\\n0         NaN       NaN     2005_07_06_11_11_Seveas_0       NaN      NaN   \n1         NaN       NaN     2005_07_06_11_11_Seveas_1       NaN      NaN   \n2         NaN       NaN  2005_07_06_11_11_monchichi_2       NaN      NaN   \n3         NaN       NaN   2005_07_06_11_11_IceDC571_3       NaN      NaN   \n4         NaN       NaN     2005_07_06_11_11_Seveas_4       NaN      NaN   \n...       ...       ...                           ...       ...      ...   \n1205   1495.0    1493.0    2005_07_06_03_35_Nige_1495    1493.0   1493.0   \n1206   1496.0    1495.0    2005_07_06_03_35_Nige_1496    1495.0   1495.0   \n1207   1497.0    1495.0    2005_07_06_03_35_Nige_1497    1495.0   1495.0   \n1208   1498.0    1498.0     2005_07_06_03_35_FLD_1498    1498.0   1498.0   \n1209   1499.0    1494.0  2005_07_06_03_35_iLLf8d_1499    1494.0   1494.0   \n\n      parent_r                      uuid_r  \n0          NaN                         NaN  \n1          NaN                         NaN  \n2          NaN                         NaN  \n3          NaN                         NaN  \n4          NaN                         NaN  \n...        ...                         ...  \n1205    1489.0  2005_07_06_03_35_Nige_1493  \n1206    1493.0  2005_07_06_03_35_Nige_1495  \n1207    1493.0  2005_07_06_03_35_Nige_1495  \n1208    1498.0   2005_07_06_03_35_FLD_1498  \n1209    1487.0  2005_07_06_03_35_wizo_1494  \n\n[1210 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>child_l</th>\n      <th>parent_l</th>\n      <th>uuid_l</th>\n      <th>file_ind</th>\n      <th>child_r</th>\n      <th>parent_r</th>\n      <th>uuid_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005_07_06_11_11_Seveas_0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005_07_06_11_11_Seveas_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005_07_06_11_11_monchichi_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005_07_06_11_11_IceDC571_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005_07_06_11_11_Seveas_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>1495.0</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n      <td>1493.0</td>\n      <td>1493.0</td>\n      <td>1489.0</td>\n      <td>2005_07_06_03_35_Nige_1493</td>\n    </tr>\n    <tr>\n      <th>1206</th>\n      <td>1496.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1496</td>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>1497.0</td>\n      <td>1495.0</td>\n      <td>2005_07_06_03_35_Nige_1497</td>\n      <td>1495.0</td>\n      <td>1495.0</td>\n      <td>1493.0</td>\n      <td>2005_07_06_03_35_Nige_1495</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>1498.0</td>\n      <td>2005_07_06_03_35_FLD_1498</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>1499.0</td>\n      <td>1494.0</td>\n      <td>2005_07_06_03_35_iLLf8d_1499</td>\n      <td>1494.0</td>\n      <td>1494.0</td>\n      <td>1487.0</td>\n      <td>2005_07_06_03_35_wizo_1494</td>\n    </tr>\n  </tbody>\n</table>\n<p>1210 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['2004-12-25', '2005-02-06', '2005-02-08', '2005-02-27', '2005-05-14', '2005-05-19', '2005-06-06', '2005-06-12', '2005-06-16', '2005-06-20', '2005-07-25', '2005-07-29', '2005-09-26', '2005-10-07', '2005-10-12', '2005-12-03', '2005-12-04', '2005-12-16', '2005-12-23', '2006-01-02', '2006-01-12', '2006-02-20', '2006-02-24', '2006-02-28', '2006-03-05', '2006-05-02', '2006-05-15', '2006-05-27', '2006-05-29', '2006-06-01', '2006-06-05', '2006-06-08', '2006-06-21', '2006-06-28', '2006-07-01', '2006-08-06', '2006-08-11', '2006-08-13', '2006-08-15', '2006-08-23', '2006-09-13', '2006-09-24', '2006-11-01', '2006-12-06', '2006-12-10', '2006-12-20', '2007-01-12', '2007-01-19', '2007-01-21', '2007-01-29', '2007-02-06', '2007-02-07', '2007-02-15', '2007-06-01', '2007-06-04', '2007-06-17', '2007-07-03', '2007-08-19', '2007-08-22', '2007-08-24', '2007-09-07', '2007-10-24', '2007-12-17', '2008-01-02', '2008-01-03', '2008-02-07', '2008-02-14', '2008-03-01', '2008-04-20', '2008-04-27', '2008-04-30', '2008-05-24', '2008-06-03', '2008-07-03', '2008-10-02', '2009-01-05', '2009-03-25', '2009-05-04', '2009-05-08', '2009-07-02', '2009-11-13', '2009-12-05', '2010-01-04', '2010-02-13', '2010-03-08', '2010-03-20', '2010-04-12', '2010-05-30', '2010-06-21', '2010-08-05', '2010-08-15', '2010-08-29', '2010-10-17', '2010-10-27', '2011-02-13', '2011-02-23', '2011-03-18', '2011-04-14', '2011-04-17', '2011-04-28', '2011-08-17', '2011-08-22', '2011-11-24', '2011-12-07', '2012-02-03', '2012-03-24', '2012-05-04', '2012-05-20', '2012-06-02', '2012-06-20', '2012-11-24', '2012-11-30', '2012-12-15', '2013-01-11', '2013-01-30', '2013-02-24', '2013-05-05', '2013-05-07', '2013-05-19', '2013-05-28', '2013-07-10', '2013-07-19', '2013-08-29', '2013-08-30', '2013-09-12', '2013-09-16', '2013-10-04', '2013-10-11', '2013-10-28', '2013-12-02', '2014-01-08', '2014-08-14', '2014-09-29', '2014-12-21', '2014-12-27', '2015-01-20', '2015-02-04', '2015-04-19', '2015-05-08', '2015-06-12', '2015-08-10', '2015-09-25', '2015-10-14', '2015-10-19', '2015-11-26', '2015-12-28', '2017-02-06', '2017-03-02', '2017-03-23', '2017-05-09', '2017-07-15', '2017-09-02', '2018-02-27', '2005-07-06', '2007-01-11', '2007-12-01', '2008-07-14', '2010-08-17', '2013-09-01', '2014-06-18', '2015-03-18', '2016-02-22', '2016-06-08', '2004-11-15', '2005-06-27', '2005-08-08', '2008-12-11', '2009-02-23', '2009-03-03', '2009-10-01', '2011-05-29', '2011-11-13', '2016-12-19'])"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df_dict.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "     parent  child\n0       999   1000\n1      1001   1002\n2      1001   1004\n3      1007   1008\n4      1007   1009\n..      ...    ...\n255    1044   1047\n256    1084   1084\n257    1172   1172\n258     999    999\n259     982    982\n\n[260 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>child</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>999</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>1002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001</td>\n      <td>1004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1007</td>\n      <td>1008</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1007</td>\n      <td>1009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>1044</td>\n      <td>1047</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>1084</td>\n      <td>1084</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>1172</td>\n      <td>1172</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>999</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>982</td>\n      <td>982</td>\n    </tr>\n  </tbody>\n</table>\n<p>260 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "user_map_path = '../data/cleaned/users.csv'\n",
    "map_df = pd.read_csv(user_map_path, index_col=0)\n",
    "users_map = dict(zip(map_df['user_txt'], map_df['user_id']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0       15358\n1       15358\n2        7927\n3       16253\n4       15358\n        ...  \n1516     3459\n1517     3459\n1518     3459\n1519    10757\n1520    10875\nName: user, Length: 1521, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['user'].map(users_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
